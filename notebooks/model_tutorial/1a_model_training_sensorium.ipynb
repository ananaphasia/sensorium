{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# How to train the Baseline Models for the SENSORIUM track"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### This notebook will show how to\n",
    "- instantiate dataloader for the Sensorium track\n",
    "- instantiate pytorch model\n",
    "- instantiate a trainer function\n",
    "- train two baselines for this competition track\n",
    "- save the model weights (the model weights can already be found in './model_checkpoints/pretrained/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from nnfabrik.builder import get_data, get_model, get_trainer\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "current_path = os.getcwd()\n",
    "# Identify if path has 'sensorium' as a folder in it\n",
    "if 'sensorium' in current_path:\n",
    "    # If so, set the path to the root of the repo\n",
    "    current_path = current_path.split('sensorium')[0] + 'sensorium'\n",
    "else:\n",
    "    raise FileNotFoundError(\n",
    "        'This needs to be run from within the sensorium folder')\n",
    "os.chdir(current_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Instantiate DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# loading the SENSORIUM dataset\n",
    "\n",
    "filenames = [\n",
    "    # 'notebooks/data/static23964-4-22-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip',\n",
    "    'notebooks/data/IM_prezipped/LPE11086/2023_12_16/'\n",
    "]\n",
    "\n",
    "\n",
    "dataset_fn = 'sensorium.datasets.static_loaders'\n",
    "dataset_config = {'paths': filenames,\n",
    "\n",
    "\n",
    "                  'normalize': True,\n",
    "\n",
    "\n",
    "                  'include_behavior': False,\n",
    "\n",
    "\n",
    "                  'include_eye_position': False,\n",
    "\n",
    "\n",
    "                  'batch_size': 128,\n",
    "\n",
    "\n",
    "                  'scale': 0.25,\n",
    "\n",
    "\n",
    "                  }\n",
    "\n",
    "\n",
    "dataloaders_sens = get_data(dataset_fn, dataset_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the SENSORIUM dataset\n",
    "\n",
    "filenames = [\n",
    "    # 'notebooks/data/static23964-4-22-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip',\n",
    "    'notebooks/data/IM_prezipped/LPE11086/2023_12_16/'\n",
    "]\n",
    "\n",
    "\n",
    "dataset_fn = 'sensorium.datasets.static_loaders'\n",
    "dataset_config = {'paths': filenames,\n",
    "                  'normalize': True,\n",
    "                  'include_behavior': False,\n",
    "                  'include_eye_position': False,\n",
    "                  'batch_size': 128,\n",
    "                  'scale': 0.25,\n",
    "                  }\n",
    "\n",
    "\n",
    "dataloaders = get_data(dataset_fn, dataset_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Instantiate State of the Art Model (SOTA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_fn = 'sensorium.models.stacked_core_full_gauss_readout'\n",
    "model_config = {'pad_input': False,\n",
    "                'stack': -1,\n",
    "                'layers': 4,\n",
    "                'input_kern': 9,\n",
    "                'gamma_input': 6.3831,\n",
    "                'gamma_readout': 0.0076,\n",
    "                'hidden_kern': 7,\n",
    "                'hidden_channels': 64,\n",
    "                'depth_separable': True,\n",
    "                'grid_mean_predictor': {'type': 'cortex',\n",
    "                                        'input_dimensions': 2,\n",
    "                                        'hidden_layers': 1,\n",
    "                                        'hidden_features': 30,\n",
    "                                        'final_tanh': True},\n",
    "                'init_sigma': 0.1,\n",
    "                'init_mu_range': 0.3,\n",
    "                'gauss_type': 'full',\n",
    "                'shifter': False,\n",
    "                }\n",
    "\n",
    "model = get_model(model_fn=model_fn,\n",
    "                  model_config=model_config,\n",
    "                  dataloaders=dataloaders,\n",
    "                  seed=42,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Configure Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "trainer_fn = \"sensorium.training.standard_trainer\"\n",
    "\n",
    "trainer_config = {'max_iter': 200,\n",
    "                  'verbose': True,\n",
    "                  'lr_decay_steps': 4,\n",
    "                  'avg_loss': False,\n",
    "                  'lr_init': 0.009,\n",
    "                  }\n",
    "\n",
    "trainer = get_trainer(trainer_fn=trainer_fn,\n",
    "                      trainer_config=trainer_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Run model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   6%|▌         | 2/33 [00:14<03:40,  7.10s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m validation_score, trainer_output, state_dict \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\asimo\\Documents\\BCCN\\Lab Rotations\\Petreanu Lab\\sensorium\\sensorium\\training\\trainers.py:183\u001b[0m, in \u001b[0;36mstandard_trainer\u001b[1;34m(model, dataloaders, seed, avg_loss, scale_loss, loss_function, stop_function, loss_accum_batch_n, device, verbose, interval, patience, epoch, lr_init, max_iter, maximize, tolerance, restore_best, lr_decay_steps, lr_decay_factor, min_lr, cb, track_training, detach_core, **kwargs)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;66;03m# train over batches\u001b[39;00m\n\u001b[0;32m    182\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m--> 183\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_no, (data_key, data) \u001b[38;5;129;01min\u001b[39;00m tqdm(\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;28menumerate\u001b[39m(LongCycler(dataloaders[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m])),\n\u001b[0;32m    185\u001b[0m     total\u001b[38;5;241m=\u001b[39mn_iterations,\n\u001b[0;32m    186\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch),\n\u001b[0;32m    187\u001b[0m ):\n\u001b[0;32m    189\u001b[0m     batch_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(data)\n\u001b[0;32m    190\u001b[0m     batch_kwargs \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39m_asdict() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\asimo\\.conda\\envs\\molanalysis\\lib\\site-packages\\tqdm\\std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1175\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1178\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1179\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1180\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1181\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\asimo\\.conda\\envs\\molanalysis\\lib\\site-packages\\neuralpredictors\\training\\cyclers.py:85\u001b[0m, in \u001b[0;36mLongCycler.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     79\u001b[0m cycles \u001b[38;5;241m=\u001b[39m [cycle(loader) \u001b[38;5;28;01mfor\u001b[39;00m loader \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloaders\u001b[38;5;241m.\u001b[39mvalues()]\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, loader, _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\n\u001b[0;32m     81\u001b[0m     cycle(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloaders\u001b[38;5;241m.\u001b[39mkeys()),\n\u001b[0;32m     82\u001b[0m     (cycle(cycles)),\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloaders) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_batches),\n\u001b[0;32m     84\u001b[0m ):\n\u001b[1;32m---> 85\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m k, \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\asimo\\.conda\\envs\\molanalysis\\lib\\site-packages\\neuralpredictors\\training\\cyclers.py:6\u001b[0m, in \u001b[0;36mcycle\u001b[1;34m(iterable)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m----> 6\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m      8\u001b[0m         iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(iterable)\n",
      "File \u001b[1;32mc:\\Users\\asimo\\.conda\\envs\\molanalysis\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\asimo\\.conda\\envs\\molanalysis\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\asimo\\.conda\\envs\\molanalysis\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\asimo\\.conda\\envs\\molanalysis\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\asimo\\.conda\\envs\\molanalysis\\lib\\site-packages\\neuralpredictors\\data\\datasets\\base.py:418\u001b[0m, in \u001b[0;36mFileTreeDatasetBase.__getitem__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    417\u001b[0m     datapath \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresolve_data_path(data_key)\n\u001b[1;32m--> 418\u001b[0m     val \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatapath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m.npy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_cache:\n\u001b[0;32m    420\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache[data_key][item] \u001b[38;5;241m=\u001b[39m val\n",
      "File \u001b[1;32mc:\\Users\\asimo\\.conda\\envs\\molanalysis\\lib\\site-packages\\numpy\\lib\\npyio.py:405\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[0;32m    403\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    404\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 405\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    406\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    408\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "validation_score, trainer_output, state_dict = trainer(\n",
    "    model, dataloaders, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18121223"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Save model checkpoints after training is complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\asimo\\\\Documents\\\\BCCN\\\\Lab Rotations\\\\Petreanu Lab\\\\sensorium'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), './model_checkpoints/sensorium_sota_model.pth')\n",
    "torch.save(model.state_dict(),\n",
    "           'notebooks/model_tutorial/model_checkpoints/IM_sota_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load Model Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.load_state_dict(torch.load(\"./model_checkpoints/pretrained/sensorium_sota_model.pth\"));\n",
    "model.load_state_dict(torch.load(\n",
    "    'notebooks/model_tutorial/model_checkpoints/IM_sota_model.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Train a simple LN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Our LN model has the same architecture as our CNN model (a convolutional core followed by a gaussian readout)\n",
    "but with all non-linearities removed except the final ELU+1 nonlinearity.\n",
    "Thus turning the CNN model effectively into a fully linear model followed by a single output non-linearity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_fn = 'sensorium.models.stacked_core_full_gauss_readout'\n",
    "model_config = {'pad_input': False,\n",
    "                'stack': -1,\n",
    "                'layers': 3,\n",
    "                'input_kern': 9,\n",
    "                'gamma_input': 6.3831,\n",
    "                'gamma_readout': 0.0076,\n",
    "                'hidden_kern': 7,\n",
    "                'hidden_channels': 64,\n",
    "                'grid_mean_predictor': {'type': 'cortex',\n",
    "                                        'input_dimensions': 2,\n",
    "                                        'hidden_layers': 1,\n",
    "                                        'hidden_features': 30,\n",
    "                                        'final_tanh': True},\n",
    "                'depth_separable': True,\n",
    "                'init_sigma': 0.1,\n",
    "                'init_mu_range': 0.3,\n",
    "                'gauss_type': 'full',\n",
    "                'linear': True\n",
    "                }\n",
    "model = get_model(model_fn=model_fn,\n",
    "                  model_config=model_config,\n",
    "                  dataloaders=dataloaders,\n",
    "                  seed=42,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 33/33 [00:02<00:00, 14.70it/s]\n",
      "Epoch 2: 100%|██████████| 33/33 [00:02<00:00, 14.78it/s]\n",
      "Epoch 3: 100%|██████████| 33/33 [00:02<00:00, 15.34it/s]\n",
      "Epoch 4: 100%|██████████| 33/33 [00:02<00:00, 14.89it/s]\n",
      "Epoch 5: 100%|██████████| 33/33 [00:02<00:00, 15.81it/s]\n",
      "Epoch 6: 100%|██████████| 33/33 [00:02<00:00, 15.23it/s]\n",
      "Epoch 7: 100%|██████████| 33/33 [00:02<00:00, 15.88it/s]\n",
      "Epoch 8: 100%|██████████| 33/33 [00:02<00:00, 15.53it/s]\n",
      "Epoch 9: 100%|██████████| 33/33 [00:02<00:00, 14.87it/s]\n",
      "Epoch 10: 100%|██████████| 33/33 [00:02<00:00, 15.68it/s]\n",
      "Epoch 11: 100%|██████████| 33/33 [00:02<00:00, 15.45it/s]\n",
      "Epoch 12: 100%|██████████| 33/33 [00:02<00:00, 14.19it/s]\n",
      "Epoch 13: 100%|██████████| 33/33 [00:02<00:00, 14.21it/s]\n",
      "Epoch 14: 100%|██████████| 33/33 [00:02<00:00, 13.30it/s]\n",
      "Epoch 15: 100%|██████████| 33/33 [00:02<00:00, 15.27it/s]\n",
      "Epoch 16: 100%|██████████| 33/33 [00:02<00:00, 14.72it/s]\n",
      "Epoch 17: 100%|██████████| 33/33 [00:02<00:00, 15.17it/s]\n",
      "Epoch 18: 100%|██████████| 33/33 [00:02<00:00, 14.41it/s]\n",
      "Epoch 19: 100%|██████████| 33/33 [00:02<00:00, 14.22it/s]\n",
      "Epoch 20: 100%|██████████| 33/33 [00:02<00:00, 14.58it/s]\n",
      "Epoch 21: 100%|██████████| 33/33 [00:02<00:00, 14.78it/s]\n",
      "Epoch 22: 100%|██████████| 33/33 [00:02<00:00, 15.45it/s]\n",
      "Epoch 23: 100%|██████████| 33/33 [00:02<00:00, 14.91it/s]\n",
      "Epoch 24: 100%|██████████| 33/33 [00:02<00:00, 15.14it/s]\n",
      "Epoch 25: 100%|██████████| 33/33 [00:02<00:00, 15.76it/s]\n",
      "Epoch 26: 100%|██████████| 33/33 [00:02<00:00, 14.79it/s]\n",
      "Epoch 27: 100%|██████████| 33/33 [00:02<00:00, 15.72it/s]\n",
      "Epoch 28: 100%|██████████| 33/33 [00:02<00:00, 14.46it/s]\n",
      "Epoch 29: 100%|██████████| 33/33 [00:02<00:00, 15.55it/s]\n",
      "Epoch 30: 100%|██████████| 33/33 [00:02<00:00, 15.68it/s]\n",
      "Epoch 31: 100%|██████████| 33/33 [00:02<00:00, 14.51it/s]\n",
      "Epoch 32: 100%|██████████| 33/33 [00:02<00:00, 15.73it/s]\n",
      "Epoch 33: 100%|██████████| 33/33 [00:02<00:00, 14.88it/s]\n",
      "Epoch 34: 100%|██████████| 33/33 [00:02<00:00, 14.88it/s]\n",
      "Epoch 35: 100%|██████████| 33/33 [00:02<00:00, 14.75it/s]\n",
      "Epoch 36: 100%|██████████| 33/33 [00:02<00:00, 14.59it/s]\n",
      "Epoch 37: 100%|██████████| 33/33 [00:02<00:00, 14.94it/s]\n",
      "Epoch 38: 100%|██████████| 33/33 [00:02<00:00, 14.97it/s]\n",
      "Epoch 39: 100%|██████████| 33/33 [00:02<00:00, 14.91it/s]\n",
      "Epoch 40: 100%|██████████| 33/33 [00:02<00:00, 15.30it/s]\n",
      "Epoch 41: 100%|██████████| 33/33 [00:02<00:00, 14.83it/s]\n",
      "Epoch 42: 100%|██████████| 33/33 [00:02<00:00, 15.41it/s]\n",
      "Epoch 43: 100%|██████████| 33/33 [00:02<00:00, 14.50it/s]\n",
      "Epoch 44: 100%|██████████| 33/33 [00:02<00:00, 15.04it/s]\n",
      "Epoch 45: 100%|██████████| 33/33 [00:02<00:00, 14.68it/s]\n",
      "Epoch 46: 100%|██████████| 33/33 [00:02<00:00, 14.19it/s]\n",
      "Epoch 47: 100%|██████████| 33/33 [00:02<00:00, 15.13it/s]\n",
      "Epoch 48: 100%|██████████| 33/33 [00:02<00:00, 15.46it/s]\n",
      "Epoch 49: 100%|██████████| 33/33 [00:02<00:00, 14.68it/s]\n",
      "Epoch 50: 100%|██████████| 33/33 [00:02<00:00, 15.14it/s]\n",
      "Epoch 51: 100%|██████████| 33/33 [00:02<00:00, 14.53it/s]\n",
      "Epoch 52: 100%|██████████| 33/33 [00:02<00:00, 15.50it/s]\n",
      "Epoch 53: 100%|██████████| 33/33 [00:02<00:00, 15.07it/s]\n",
      "Epoch 54: 100%|██████████| 33/33 [00:02<00:00, 14.57it/s]\n",
      "Epoch 55: 100%|██████████| 33/33 [00:02<00:00, 15.62it/s]\n"
     ]
    }
   ],
   "source": [
    "validation_score, trainer_output, state_dict = trainer(\n",
    "    model, dataloaders, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.120164454"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), './model_checkpoints/sensorium_ln_model.pth')\n",
    "torch.save(model.state_dict(),\n",
    "           'notebooks/model_tutorial/model_checkpoints/IM_ln_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.load_state_dict(torch.load(\"./model_checkpoints/pretrained/sensorium_ln_model.pth\"));\n",
    "model.load_state_dict(torch.load(\n",
    "    'notebooks/model_tutorial/model_checkpoints/IM_ln_model.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
